import React from "react";

import Button from "direct-core/UI/Button";

function createAudioMeter(audioContext,clipLevel,averaging,clipLag) {
	var processor = audioContext.createScriptProcessor(512);
	processor.onaudioprocess = volumeAudioProcess;
	processor.clipping = false;
	processor.lastClip = 0;
	processor.volume = 0;
	processor.clipLevel = clipLevel || 0.98;
	processor.averaging = averaging || 0.95;
	processor.clipLag = clipLag || 750;

	// this will have no effect, since we don't copy the input to the output,
	// but works around a current Chrome bug.
	processor.connect(audioContext.destination);

	processor.checkClipping = function(){
			if( !this.clipping ){
				return false;
      }
			if( ( this.lastClip + this.clipLag ) < window.performance.now() ){
				this.clipping = false;
      }
			return this.clipping;
		};

	processor.shutdown = function(){
			this.disconnect();
			this.onaudioprocess = null;
		};
	return processor;
}

function volumeAudioProcess( event ) {
	var buf = event.inputBuffer.getChannelData(0);
  var bufLength = buf.length;
	var sum = 0;
  var x;

	// Do a root-mean-square on the samples: sum up the squares...
  for( let i=0; i < bufLength ; i++ ){
  	x = buf[i];
  	if( Math.abs(x) >= this.clipLevel ){
  		this.clipping = true;
  	}
  	sum += x * x;
  }

  // ... then take the square root of the sum.
  var rms =  Math.sqrt(sum / bufLength);

  // Now smooth this out with the averaging factor applied
  // to the previous sample - take the max here because we
  // want "fast attack, slow release."
  this.volume = Math.max( rms , this.volume * this.averaging );
}

class RecordVoice extends React.PureComponent {
  reader = new FileReader()
  chunks = []

  lastVolume = 0
  getAudio = ref => this.audio = ref

  componentDidMount(){
    navigator.mediaDevices.getUserMedia({
      audio: true
    }).then( stream => {
        this.stream = stream
        this.mediaRecorder = new MediaRecorder( stream )
        let audioCtx = new AudioContext();
        let mediaStreamSource = audioCtx.createMediaStreamSource( stream.clone() )
        this.meter = createAudioMeter( audioCtx )

        mediaStreamSource.connect( this.meter )
        this.mediaRecorder.ondataavailable = ev => {
          this.chunks.push( ev.data )
        }

    }).catch( err => {
      console.log( err );
    })

    setInterval( () => this.analysis() , 1 )
    //this.reader.onloadend = () => {
    //  const data = this.reader.result;
    //  console.log( data );
    //  const audioCtx = new AudioContext()
    //  const source = audioCtx.createBufferSource();
    //  const scriptNode = audioCtx.createScriptProcessor();

    //  audioCtx.decodeAudioData( data , buffer => {
    //    source.buffer = buffer;
    //  })

    //  source.connect( scriptNode );
    //  scriptNode.connect( audioCtx.destination );
    //  scriptNode.onaudioprocess = ev => {

    //    const inputData = ev.inputBuffer.getChannelData( 0 );
    //    for( let c= 0 ; c < ev.inputBuffer.numOfChannels ; c ++ ){
    //      for( let sample = 0 ; sample < ev.inputBuffer.length ; sample++ ){
    //        console.log( inputData[sample] );
    //      }
    //    }
    //    source.buffer = null
    //    scriptNode.onaudioprocess = null
    //  }
    //  source.start()
    //}
  }

  i = 0;
  analysis( /*data*/ ){
    //this.reader.readAsArrayBuffer( data );
    //if( !this.meter ){
    //  return
    //}
    //if( this.meter.volume < 10 ){
    //  this.i++;

    //}
    //if( Math.abs( this.meter.volume - this.lastVolume ) > 10 ){
      console.log( this.meter.volume );
    //}
  }

  startRecord = () => {
    switch( this.mediaRecorder.state ){
      case "paused":
        this.mediaRecorder.resume();
        break;
      case "inactive":
        this.mediaRecorder.start();
        break;
    }
    this.handle = setInterval( () => {
      //if( this.i >= 600 ){
      //  this.i = 0;
      //  clearInterval( this.handle );
      //  this.mergeRecords();
      //  return;
      //}
      this.mediaRecorder.requestData();
    } , 600 );
  }

  stopReord = () => {
    if( this.mediaRecorder.state === "inactive" ){
      return
    }
    this.mediaRecorder.stop();
    clearInterval( this.handle );
  }

  mergeRecords = () => {
    this.stopReord();
    var blob = new Blob( this.chunks , {
      type: "audio/ogg; codecs=opus"
    });
    console.log( blob );
    console.log( this.chunks )
    this.chunks = [];

    var audioURL = URL.createObjectURL( blob );
    this.audio.src = audioURL;
    //this.analysis( blob );
    this.startRecord();
  }

  render(){
    return (
      <React.Fragment>
        <Button
          onClick={this.startRecord}
          text="开始"
        />
        <Button
          onClick={this.mergeRecords}
          text="合成"
        />
        <Button
          onClick={this.stopReord}
          text="终止"
        />
        <div>
          <span>Main audio</span>
          <audio
            controls
            ref={this.getAudio}
          />
        </div>
      </React.Fragment>
    )
  }
};

export default RecordVoice;
